# ==============================================================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: Import ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
# ==============================================================================
import requests
import pandas as pd
from transformers import pipeline


# ==============================================================================
# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2.1: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data "Collector" via API)
# ==============================================================================
def get_data_from_api(keyword, api_key):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏ú‡πà‡∏≤‡∏ô NewsAPI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
    ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡∏Ç‡∏≠‡∏á Pandas ‡∏ó‡∏µ‡πà‡∏°‡∏µ 'title' ‡πÅ‡∏•‡∏∞ 'timestamp'
    """
    url = f'https://newsapi.org/v2/everything?q={keyword}&language=th&sortBy=publishedAt&apiKey={api_key}'
    print(f"üöÄ [Step 2.1] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤: '{keyword}' ‡∏à‡∏≤‡∏Å NewsAPI...")


    try:
        response = requests.get(url)
        data = response.json()


        if data['status'] == 'ok':
            articles = data.get('articles', [])
            if not articles:
                return pd.DataFrame() # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ DataFrame ‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏Ç‡πà‡∏≤‡∏ß


            # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏î‡πâ‡∏ß‡∏¢ Pandas
            df = pd.DataFrame(articles)
            df = df[['title', 'publishedAt']] # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            df = df.rename(columns={'publishedAt': 'timestamp'}) # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
            print(f"‚úÖ [Step 2.1] ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡πÑ‡∏î‡πâ‡∏°‡∏≤ {len(df)} ‡∏Ç‡πà‡∏≤‡∏ß")
            return df
        else:
            print(f"üö® [Step 2.1] Error ‡∏à‡∏≤‡∏Å API: {data.get('message')}")
            return pd.DataFrame()


    except Exception as e:
        print(f"üö® [Step 2.1] ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠: {e}")
        return pd.DataFrame()


# ==============================================================================
# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2.2: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å (Sentiment Analyzer)
# ==============================================================================
def analyze_sentiment_and_update_df(df):
    """
    ‡∏£‡∏±‡∏ö DataFrame ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤, ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'title',
    ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'sentiment' ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô DataFrame ‡πÄ‡∏î‡∏¥‡∏°
    """
    print("\nüß† [Step 2.2] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å...")
    sentiment_analyzer = pipeline(
        "sentiment-analysis",
        model="lxyuan/distilbert-base-multilingual-cased-sentiments-student"
    )
   
    titles = df['title'].tolist()
    print("...‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å...")
    results = sentiment_analyzer(titles)
   
    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 'label' (‡πÄ‡∏ä‡πà‡∏ô 'POSITIVE', 'NEGATIVE') ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
    sentiments = [result['label'].upper() for result in results]
    df['sentiment'] = sentiments
   
    print("‚úÖ [Step 2.2] ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    return df


# ==============================================================================
# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2.3: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (Anomaly Detector)
# ==============================================================================
def detect_anomalies(df):
    """
    ‡∏£‡∏±‡∏ö DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
    """
    print("\nüïµÔ∏è  [Step 2.3] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥...")
    if df.empty or 'sentiment' not in df.columns:
        print("...‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
        return


    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå timestamp ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà Python ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df.set_index('timestamp', inplace=True)


    # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß 'NEGATIVE' ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
    negative_counts_per_hour = df[df['sentiment'] == 'NEGATIVE'].resample('h').size()
   
    if len(negative_counts_per_hour) < 2:
        print("...‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ Baseline")
        return
       
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ Baseline
    mean_negatives = negative_counts_per_hour.mean()
    std_dev_negatives = negative_counts_per_hour.std()
   
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏Å‡∏ì‡∏ë‡πå (Threshold)
    threshold = mean_negatives + (2 * std_dev_negatives)
   
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    last_hour_count = negative_counts_per_hour.iloc[-1]
   
    print(f"...‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö‡∏ï‡πà‡∏≠‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á: {mean_negatives:.2f}")
    print(f"...‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô (Threshold): {threshold:.2f}")
    print(f"...‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö‡πÉ‡∏ô‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {last_hour_count}")


    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if last_hour_count > threshold and last_hour_count > 0:
        print("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
        print("!!! üö® ALERT: ‡∏û‡∏ö‡∏†‡∏≤‡∏ß‡∏∞‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥! ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö‡∏û‡∏∏‡πà‡∏á‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô !!!")
        print("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    else:
        print("\n‚úÖ [Step 2.3] ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥")


# ==============================================================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° (Main Program)
# ==============================================================================
if __name__ == "__main__":
    # 1. ‡πÉ‡∏™‡πà API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏°‡∏≤ ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
    MY_API_KEY = "91bba17953f340ffa7c7989b7c063ece" # <<<< ‡πÉ‡∏™‡πà KEY ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
    target_keyword = "AIS"


    if "YOUR_API_KEY" in MY_API_KEY:
        print("!!! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° !!!")
    else:
        # Step 2.1: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        data_df = get_data_from_api(target_keyword, MY_API_KEY)


        if not data_df.empty:
            # Step 2.2: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å
            data_df = analyze_sentiment_and_update_df(data_df)


            # Step 2.3: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
            detect_anomalies(data_df)


            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå CSV
            try:
                data_df.to_csv("pr_crisis_data.csv", encoding='utf-8-sig')
                print("\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå 'pr_crisis_data.csv' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            except Exception as e:
                print(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV: {e}")

